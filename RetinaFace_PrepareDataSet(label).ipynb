{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cba3eb3-bfab-4b07-9d49-b02a58dc5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'c:\\ai_project01\\Pytorch_Retinaface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee2fdc-88e1-46f0-904a-1b8b1fc7be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from models.retinaface import RetinaFace\n",
    "from data import cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "from utils.box_utils import decode\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c066b4-ccb1-4e25-b610-dff7d4e42a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "cfg = cfg_re50\n",
    "net = RetinaFace(cfg=cfg, phase='test').to(device)\n",
    "pretrained_path=r'C:\\ai_project01\\Pytorch_Retinaface\\weights\\Resnet50_Final.pth'\n",
    "state_dict = torch.load(pretrained_path, map_location=device, weights_only=True)\n",
    "new_state_dict={}\n",
    "for k,v in state_dict.items():\n",
    "    if k.startswith(\"module.\"):\n",
    "        new_state_dict[k[7:]] = v\n",
    "    else:\n",
    "        new_state_dict[k] = v\n",
    "net.load_state_dict(new_state_dict, strict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1c4dc-48a6-419c-9e20-b2ffd493fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "image_dirs = {\n",
    "    'mask_on' : r'C:\\ai_project01\\mask_images\\mask_on',\n",
    "    'no_mask' : r'C:\\ai_project01\\mask_images\\no_mask'\n",
    "}\n",
    "\n",
    "label_dir = r'C:\\ai_project01\\labels'\n",
    "os.makedirs(label_dir, exist_ok=True)\n",
    "class_ids = {\n",
    "    'mask_on': 0,\n",
    "    'no_mask': 1\n",
    "}\n",
    "\n",
    "for mask_status, image_dir in image_dirs.items():\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if img_file.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "            image_path = os.path.join(image_dir, img_file)\n",
    "            img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            img = np.float32(img_raw)\n",
    "            im_height, im_width, _ = img.shape\n",
    "            scale = torch.Tensor([im_width, im_height, im_width, im_height]).to(device)\n",
    "            img -= (104,117,123)\n",
    "            img = img.transpose(2,0,1)\n",
    "            img = torch.from_numpy(img).unsqueeze(0).to(device)\n",
    "            loc, conf, landms = net(img)\n",
    "            priorbox = PriorBox(cfg, image_size = (im_height, im_width))\n",
    "            priors = priorbox.forward().to(device)\n",
    "            prior_data = priors.data\n",
    "            boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "            boxes = boxes * scale\n",
    "            scores = conf.squeeze(0).data.cpu().numpy()[:,1]\n",
    "            confidence_threshold = 0.5\n",
    "            top_indices = np.where(scores > confidence_threshold)[0]\n",
    "            boxes = boxes[top_indices]\n",
    "            scores = scores[top_indices]\n",
    "            dets = np.hstack((boxes.cpu().numpy(), scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "            keep = py_cpu_nms(dets, 0.3)\n",
    "            dets = dets[keep, :]\n",
    "            yolo_labels = []\n",
    "            for b in dets:\n",
    "                x1, y1, x2, y2 = b[:4]\n",
    "                x_center = ((x1 + x2) / 2) / im_width\n",
    "                y_center = ((y1 + y2) / 2) / im_height\n",
    "                bbox_width = (x2 - x1) / im_width\n",
    "                bbox_height = (y2 - y1) / im_height\n",
    "                class_id = class_ids[mask_status]\n",
    "                yolo_labels.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\")\n",
    "            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write('\\n'.join(yolo_labels))\n",
    "            print(f\"Processed: {img_file} -> {label_path}\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32762e7-1774-47b7-bc28-ca42900de061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
